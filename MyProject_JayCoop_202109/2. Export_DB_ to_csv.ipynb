{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.1 32-bit"
  },
  "interpreter": {
   "hash": "354ddf9d7eeffc9afadb00fc527a7a2c5e84bfe125ae67ba9b562508e2857d4c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ETL phase 2: Export DB to .csv\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. import necessary modules"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#==============================================\r\n",
    "#=== Mothod 1: Install and import necessary modules\r\n",
    "#==============================================\r\n",
    "from tool_import_modules import *\r\n",
    "modules = ['os', 'pandas', 'pyodbc', 'numpy', 'glob', 'seaborn', 'matplotlib', 'logging', 'time', 'openpyxl']\r\n",
    "for module in modules:\r\n",
    "    import_neccessary_modules(module)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#==============================================\r\n",
    "#=== Mothod 2: Import modules directly\r\n",
    "#==============================================\r\n",
    "import os\r\n",
    "import pandas\r\n",
    "import pyodbc\r\n",
    "import numpy as np\r\n",
    "import glob\r\n",
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import logging\r\n",
    "import time\r\n",
    "from openpyxl import Workbook\r\n",
    "from openpyxl import load_workbook"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Set path, config, and connection"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Set path\r\n",
    "my_dbName = '0179Orders_Org'\r\n",
    "my_path = r\"C:\\MyDataFiles\\Data_JayCoop_202109\"\r\n",
    "my_path_DB = my_path + \"\\DB\"\r\n",
    "my_path_DW = my_path + \"\\DW\"\r\n",
    "my_path_cleaned = my_path + \"\\cleaned\"\r\n",
    "directors =  [my_path_DB, my_path_DW, my_path_cleaned]\r\n",
    "\r\n",
    "# Set file names\r\n",
    "log_fileName = time.strftime(\"%Y%m%d\") + '_DB.log'\r\n",
    "audit_fileName = time.strftime(\"%Y%m%d\") + '_DB_audit.xlsx'\r\n",
    "audit_fullPath = os.path.join(my_path, audit_fileName)\r\n",
    "\r\n",
    "# Set log file\r\n",
    "os.chdir(my_path)\r\n",
    "logger = logging.getLogger()\r\n",
    "while logger.hasHandlers():\r\n",
    "    logger.removeHandler(logger.handlers[0])\r\n",
    "#logger.setLevel(logging.DEBUG)\r\n",
    "# Create file handler which logs even debug messages\r\n",
    "fh = logging.FileHandler(log_fileName, 'w') # 'w'-overwrite; 'a'-append\r\n",
    "fh.setLevel(logging.INFO)\r\n",
    "# Create console handler with a higher log level\r\n",
    "ch = logging.StreamHandler()\r\n",
    "ch.setLevel(logging.DEBUG)\r\n",
    "# Create formatter and add it to the handlers\r\n",
    "formatter = logging.Formatter('%(asctime)s : [%(levelname)s] %(message)s')\r\n",
    "fh.setFormatter(formatter)\r\n",
    "ch.setFormatter(formatter)\r\n",
    "# Add the handlers to the logger\r\n",
    "logger.addHandler(fh)\r\n",
    "logger.addHandler(ch)\r\n",
    "\r\n",
    "# Check path\r\n",
    "if not os.path.exists(my_path):\r\n",
    "    os.makedirs(my_path)\r\n",
    "    logger.info(\"Directory created: \" + my_path)\r\n",
    "# Clean log files\r\n",
    "else:\r\n",
    "    logExtension = \".log\"\r\n",
    "    auditExtension = '.xlsx'\r\n",
    "    for root_folder, folders, files in os.walk(my_path):\r\n",
    "        for file in files:\r\n",
    "            file_path = os.path.join(root_folder, file)\r\n",
    "            file_extension = os.path.splitext(file)[1]\r\n",
    "            if file_extension == logExtension and file != log_fileName:\r\n",
    "                if not os.remove(file_path):\r\n",
    "                    logger.info(\"File deleted successfully: \" + file_path)\r\n",
    "                else:\r\n",
    "                    logger.info(\"Unable to delete the \" + file_path)\r\n",
    "            if file_extension == auditExtension and file != audit_fileName:\r\n",
    "                if not os.remove(file_path):\r\n",
    "                    logger.info(\"File deleted successfully: \" + file_path)\r\n",
    "                else:\r\n",
    "                    logger.info(\"Unable to delete the \" + file_path)\r\n",
    "\r\n",
    "# Check directors\r\n",
    "for director in directors:\r\n",
    "    if not os.path.exists(director):\r\n",
    "        os.makedirs(director)\r\n",
    "        logger.debug('\\nDirectory created: ' + director)\r\n",
    "# Check auditExcel\r\n",
    "if not os.path.isfile(audit_fullPath):\r\n",
    "    auditExcel = Workbook()\r\n",
    "    sheet1 = auditExcel.active\r\n",
    "    sheet1.title = 'CreatedFiles'\r\n",
    "    sheet1.append([\"File\", \"CreatedTime\", \"Path\"])\r\n",
    "    sheet2 = auditExcel.create_sheet(title=\"Cleansing\")\r\n",
    "    sheet2.append([\"Database\", \"Table\", \"Column\", \"Value\", \"Issue\"])\r\n",
    "    auditExcel.save(audit_fullPath)\r\n",
    "else:\r\n",
    "    auditExcel = load_workbook(filename = audit_fullPath)\r\n",
    "    sheet1 = auditExcel[\"CreatedFiles\"]\r\n",
    "    sheet2 = auditExcel[\"Cleansing\"]\r\n",
    "    adtExcSh1Row = sheet1.max_row\r\n",
    "    adtExcSh2Row = sheet1.max_row\r\n",
    "# Print log header\r\n",
    "logger.info('==== Extract: from DB(SQL Server) ====')\r\n",
    "# Set up SQL Server connector (DATABASE:'0179Orders_Org')\r\n",
    "os.chdir(my_path_DB)\r\n",
    "sql_conn = pyodbc.connect('DRIVER={SQL Server}; SERVER=localhost; DATABASE=0179Orders_Org; UID=sa; PWD=SQLServer2019')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-28 00:18:15,317 : [INFO] ==== Extract: from DB(SQL Server) ====\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Get table name list"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Get table name list\r\n",
    "logger.info('The tables are creating in ' + my_path_DB)\r\n",
    "tables = \"SELECT TABLE_NAME FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_TYPE = 'BASE TABLE' AND TABLE_NAME != 'sysdiagrams'\"\r\n",
    "tbls = pandas.read_sql(tables, sql_conn)\r\n",
    "print(tbls)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-28 00:18:21,221 : [INFO] The tables are creating in C:\\MyDataFiles\\Data_JayCoop_202109\\DB\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              TABLE_NAME\n",
      "0                 Orders\n",
      "1               Products\n",
      "2          Order Details\n",
      "3   CustomerCustomerDemo\n",
      "4   CustomerDemographics\n",
      "5                 Region\n",
      "6            Territories\n",
      "7    EmployeeTerritories\n",
      "8                   test\n",
      "9              Employees\n",
      "10            Categories\n",
      "11             Customers\n",
      "12              Shippers\n",
      "13             Suppliers\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Extract DB from Docker to DB\\ .CSV"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "auditExcel = load_workbook(filename = audit_fullPath)\r\n",
    "sheet1 = auditExcel[\"CreatedFiles\"]\r\n",
    "adtExcSh1Row = sheet1.max_row\r\n",
    "for index, row in tbls.iterrows():\r\n",
    "    # Read from SQL Server CCBIS\r\n",
    "    tableName = row['TABLE_NAME']\r\n",
    "    fileName = tableName + '.csv'\r\n",
    "    db_csv_fullPath = os.path.join(my_path_DB, tableName)\r\n",
    "    query = \"SELECT * FROM [dbo].[\" + row['TABLE_NAME'] + \"]\"  \r\n",
    "    logger.debug = query\r\n",
    "    logger.info('--' + str(index+1) + '. ' + tableName + '.csv')  \r\n",
    "    df = pandas.read_sql(query, sql_conn)\r\n",
    "                \r\n",
    "    # Write to DB\\*.csv\r\n",
    "    try:\r\n",
    "        df.to_csv(my_path_DB + \"\\\\\" + tableName + '.csv', index=False)\r\n",
    "        adtExcSh1Row = adtExcSh1Row + 1\r\n",
    "        sheet1.cell(row=adtExcSh1Row, column=1).value = str(tableName + '.csv')\r\n",
    "        sheet1.cell(row=adtExcSh1Row, column=2).value = time.asctime()\r\n",
    "        sheet1.cell(row=adtExcSh1Row, column=3).value = my_path_DB\r\n",
    "    except:\r\n",
    "        tb = sys.exc_info()[2]\r\n",
    "        logger.warn('**** File did NOT update successfully. Please try again after make sure file is not opened and have pomission to write. - ' + db_csv_fullPath)\r\n",
    "        continue\r\n",
    "\r\n",
    "auditExcel.save(audit_fullPath)\r\n",
    "logger.info('Extract Completed Successfully - ' + str(len(os.listdir('.'))) + ' files created in ' + my_path_DB)  "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-28 00:10:35,674 : [INFO] --1. Orders.csv\n",
      "2021-09-28 00:10:43,333 : [INFO] --2. Products.csv\n",
      "2021-09-28 00:10:44,959 : [INFO] --3. Order Details.csv\n",
      "2021-09-28 00:11:01,797 : [INFO] --4. CustomerCustomerDemo.csv\n",
      "2021-09-28 00:11:01,809 : [INFO] --5. CustomerDemographics.csv\n",
      "2021-09-28 00:11:01,816 : [INFO] --6. Region.csv\n",
      "2021-09-28 00:11:01,823 : [INFO] --7. Territories.csv\n",
      "2021-09-28 00:11:01,832 : [INFO] --8. EmployeeTerritories.csv\n",
      "2021-09-28 00:11:01,841 : [INFO] --9. test.csv\n",
      "2021-09-28 00:11:39,883 : [INFO] --10. Employees.csv\n",
      "2021-09-28 00:11:40,570 : [INFO] --11. Categories.csv\n",
      "2021-09-28 00:11:40,597 : [INFO] --12. Customers.csv\n",
      "2021-09-28 00:11:41,007 : [INFO] --13. Shippers.csv\n",
      "2021-09-28 00:11:41,018 : [INFO] --14. Suppliers.csv\n",
      "2021-09-28 00:11:41,661 : [INFO] Extract Completed Successfully - 14 files created in C:\\MyDataFiles\\Data_JayCoop_202109\\DB\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}