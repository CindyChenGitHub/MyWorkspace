{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# ETL phase 2, Data Cleaning - Missing Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#!pip install pandas\n",
    "#!pip install os\n",
    "#!pip install seaborn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Directory created: C:\\MyDataFiles\\Data_CCBIS_202107\\cleaned\nFiles in C:\\MyDataFiles\\Data_CCBIS_202107\nCDR.csv\nDimAgent.csv\nDimCustomer.csv\nDimGeography.csv\nDimHandleType.csv\nDimProduct.csv\nDimProductGroup.csv\nDimServiceType.csv\nDimSeverifyType.csv\n"
     ]
    }
   ],
   "source": [
    "#set path\n",
    "my_path = r\"C:\\MyDataFiles\\Data_CCBIS_202107\"\n",
    "my_path_cleaned = my_path + \"\\cleaned\"\n",
    "if not os.path.exists(my_path_cleaned):\n",
    "    os.makedirs(my_path_cleaned)\n",
    "    print('Directory created: ' + my_path_cleaned)\n",
    "os.chdir(my_path)\n",
    "\n",
    "print('Files in ' + my_path)\n",
    "for file in glob.glob(\"*.csv\"):\n",
    "    print(file)\n",
    "\n"
   ]
  },
  {
   "source": [
    "## --Cleaning Duplicate Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==== Cleaning Duplicate Data ====\n",
      "\n",
      "From: CDR.csv(16001, 18)\n",
      "To:   CDR_clean.csv(16000, 18)\n",
      "\n",
      "From: DimAgent.csv(102, 5)\n",
      "To:   DimAgent_clean.csv(102, 5)\n",
      "\n",
      "From: DimCustomer.csv(18484, 29)\n",
      "To:   DimCustomer_clean.csv(18484, 29)\n",
      "\n",
      "From: DimGeography.csv(655, 10)\n",
      "To:   DimGeography_clean.csv(655, 10)\n",
      "\n",
      "From: DimHandleType.csv(3, 2)\n",
      "To:   DimHandleType_clean.csv(3, 2)\n",
      "\n",
      "From: DimProduct.csv(25, 3)\n",
      "To:   DimProduct_clean.csv(25, 3)\n",
      "\n",
      "From: DimProductGroup.csv(5, 2)\n",
      "To:   DimProductGroup_clean.csv(5, 2)\n",
      "\n",
      "From: DimServiceType.csv(16, 2)\n",
      "To:   DimServiceType_clean.csv(16, 2)\n",
      "\n",
      "From: DimSeverifyType.csv(3, 2)\n",
      "To:   DimSeverifyType_clean.csv(3, 2)\n"
     ]
    }
   ],
   "source": [
    "# Cleaning Duplicate Data\n",
    "os.chdir(my_path)\n",
    "print(\"==== Cleaning Duplicate Data ====\")\n",
    "for file in glob.glob(\"*.csv\"):\n",
    "\n",
    "    # get file\n",
    "    df = pd.read_csv(file)\n",
    "    print('\\nFrom: ' + file + str(df.shape))\n",
    "\n",
    "    # drop duplicate\n",
    "    df.drop_duplicates(keep=\"first\", inplace=True)\n",
    "\n",
    "    # set new file path\n",
    "    fileName = file\n",
    "    newFileName = str(fileName)[:-4] + \"_clean.csv\"\n",
    "    os.chdir(my_path_cleaned)\n",
    "    file = newFileName\n",
    "\n",
    "    # write to the csf if need\n",
    "    df.to_csv(file, index=False) \n",
    "    print('To:   ' + file + str(df.shape))\n",
    "\n",
    "    os.chdir(my_path)"
   ]
  },
  {
   "source": [
    "## -- Cleaning Missing Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==== Cleaning Missing Data ====\n",
      "\n",
      "From: CDR.csv(16001, 18)\n",
      "--CDR.csv NPS - 0%, 8\n",
      "  filled with 6.0\n",
      "To:   CDR_clean.csv(16001, 19)\n",
      "\n",
      "From: DimAgent.csv(102, 5)\n",
      "To:   DimAgent_clean.csv(102, 5)\n",
      "\n",
      "From: DimCustomer.csv(18484, 29)\n",
      "--DimCustomer.csv Title - 99%, 18383\n",
      "  filled with \"Mr.\"\n",
      "--DimCustomer.csv MiddleName - 42%, 7830\n",
      "  filled with \"A\"\n",
      "--DimCustomer.csv LastName - 0%, 1\n",
      "  filled with \"Diaz\"\n",
      "--DimCustomer.csv Suffix - 100%, 18481\n",
      "  filled with \"Jr.\"\n",
      "--DimCustomer.csv AddressLine2 - 98%, 18172\n",
      "  filled with \"Verkaufsabteilung\"\n",
      "To:   DimCustomer_clean.csv(18484, 34)\n",
      "\n",
      "From: DimGeography.csv(655, 10)\n",
      "To:   DimGeography_clean.csv(655, 10)\n",
      "\n",
      "From: DimHandleType.csv(3, 2)\n",
      "To:   DimHandleType_clean.csv(3, 2)\n",
      "\n",
      "From: DimProduct.csv(25, 3)\n",
      "To:   DimProduct_clean.csv(25, 3)\n",
      "\n",
      "From: DimProductGroup.csv(5, 2)\n",
      "To:   DimProductGroup_clean.csv(5, 2)\n",
      "\n",
      "From: DimServiceType.csv(16, 2)\n",
      "To:   DimServiceType_clean.csv(16, 2)\n",
      "\n",
      "From: DimSeverifyType.csv(3, 2)\n",
      "To:   DimSeverifyType_clean.csv(3, 2)\n"
     ]
    }
   ],
   "source": [
    "# Cleaning Missing Date\n",
    "\n",
    "os.chdir(my_path)\n",
    "print(\"==== Cleaning Missing Data ====\")\n",
    "colours = ['#000099', '#ffff00'] # specify the colours - yellow is missing. blue is not missing.\n",
    "\n",
    "# Set loop to clean all csv data files\n",
    "for file in glob.glob(\"*.csv\"):\n",
    "\n",
    "    # read the data\n",
    "    df = pd.read_csv(file)\n",
    "    cols = df.columns\n",
    "    print('\\nFrom: ' + file + str(df.shape))\n",
    "\n",
    "    # set numeric columns\n",
    "    df_numeric = df.select_dtypes(include=[np.number])\n",
    "    numeric_cols = df_numeric.columns.values\n",
    "   \n",
    "    # set non numeric columns\n",
    "    df_non_numeric = df.select_dtypes(exclude=[np.number])\n",
    "    non_numeric_cols = df_non_numeric.columns.values\n",
    "     \n",
    "    for col in df.columns:\n",
    "        missing = df[col].isnull()\n",
    "        num_missing = np.sum(missing)\n",
    "        pct_missing = np.mean(missing)\n",
    "       \n",
    "        \n",
    "        if num_missing > 0: \n",
    "\n",
    "            # Print Missing Data Percentage List - % of missing.\n",
    "            print('--' + file + ' {} - {}%'.format(col, round(pct_missing*100)) + ', ' + str(num_missing))\n",
    "            df['{}_ismissing'.format(col)] = missing\n",
    "\n",
    "            # When numeric, fill with midian value \n",
    "            if col in numeric_cols:\n",
    "                med = df[col].median()\n",
    "                df[col] = df[col].fillna(med)\n",
    "                print('  filled with ' + str(med))\n",
    "            # When not numeric, fill with most frequent value     \n",
    "            else:\n",
    "                top = df[col].describe()['top'] # impute with the most frequent value.\n",
    "                df[col] = df[col].fillna(top)\n",
    "                print('  filled with \"' + top + '\"')\n",
    "\n",
    "\n",
    "    # set new file path\n",
    "    fileName = file\n",
    "    newFileName = str(fileName)[:-4] + \"_clean.csv\"\n",
    "    os.chdir(my_path_cleaned)\n",
    "    file = newFileName\n",
    "\n",
    "    # write to the csf if need\n",
    "    df.to_csv(file, index=False) \n",
    "    print('To:   ' + file + str(df.shape))\n",
    "\n",
    "    os.chdir(my_path)\n",
    "\n",
    "\n",
    "            #print('created missing indicator for: {}'.format(col))\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    #sns.heatmap(df[cols].isnull(), cmap=sns.color_palette(colours))\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    # then based on the indicator, plot the histogram of missing values\n",
    "    #ismissing_cols = [col for col in df.columns if 'missing' in col]\n",
    "    #print(ismissing_cols)\n",
    "    #df['pct_missing'] = df[ismissing_cols].sum(axis=1)\n",
    "    #print(df['pct_missing'])\n",
    "\n",
    "    #df['pct_missing'].value_counts().reset_index().sort_values(by='index').plot.bar(x='index', y='pct_missing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}