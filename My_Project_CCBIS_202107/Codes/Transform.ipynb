{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.1 32-bit"
  },
  "interpreter": {
   "hash": "354ddf9d7eeffc9afadb00fc527a7a2c5e84bfe125ae67ba9b562508e2857d4c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=============================================================================\n",
    "#=== Install and import necessary modules\n",
    "#=============================================================================\n",
    "from import_neccessary_modules import *\n",
    "modules = ['os', 'pandas', 'pyodbc', 'numpy', 'glob', 'csv', 'tarfile', 'docker']\n",
    "for module in modules:\n",
    "    import_neccessary_modules(module)\n",
    "\n",
    "import numpy as np\n",
    "import docker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas\n",
    "import pyodbc\n",
    "import numpy as np\n",
    "import glob\n",
    "import csv\n",
    "import tarfile\n",
    "import docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename(data, oldnames, newname):\n",
    "    if type(oldnames) == str: # Input can be a string or list of strings\n",
    "        oldnames = [oldnames] # When renaming multiple columns\n",
    "        newname = [newname] # Make sure you pass the corresponding list of new names\n",
    "    i = 0\n",
    "    for name in oldnames:\n",
    "        oldvar = [c for c in data.columns if name in c]\n",
    "        if len(oldvar) == 0:\n",
    "            raise ValueError(\"Sorry, couldn't find that column in the dataset\")\n",
    "        if len(oldvar) > 1: # Doesn't have to be an exact match\n",
    "            print(\"Found multiple columns that matched \" + str(name) + \": \")\n",
    "            for c in oldvar:\n",
    "                print(str(oldvar.index(c)) + \": \" + str(c))\n",
    "            ind = input('Please enter the index of the column you would like to rename: ')\n",
    "            oldvar = oldvar[int(ind)]\n",
    "        if len(oldvar) == 1:\n",
    "            oldvar = oldvar[0]\n",
    "        data = data.rename(columns = {oldvar : newname[i]})\n",
    "        i += 1\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path\n",
    "my_path = r\"C:\\MyDataFiles\\Data_CCBIS_202107\"\n",
    "if not os.path.exists(my_path):\n",
    "    os.makedirs(my_path)\n",
    "    print(\"Directory created: \" + my_path)\n",
    "# Create data directors\n",
    "my_path_CCBIS = my_path + \"\\CCBIS\"\n",
    "my_path_CCBISDW = my_path + \"\\CCBISDW\"\n",
    "my_path_cleaned = my_path + \"\\cleaned\"\n",
    "directors =  [my_path_CCBIS, my_path_CCBISDW, my_path_cleaned]\n",
    "for director in directors:\n",
    "    if not os.path.exists(director):\n",
    "        os.makedirs(director)\n",
    "        print('Directory created: ' + director)\n",
    "# Set up SQL Server connector\n",
    "sql_conn = pyodbc.connect('DRIVER={SQL Server}; SERVER=localhost; DATABASE=CCBIS; UID=sa; PWD=SQLServer2019') \n",
    "sql_dw_conn = pyodbc.connect('DRIVER={SQL Server}; SERVER=localhost; DATABASE=CCBISDW; UID=sa; PWD=SQLServer2019')   \n",
    "# Set up transform tables\n",
    "mergeTables = {\n",
    "    1: {\n",
    "        \"mergeFrom\":    \"DimGeography_clean.csv\",\n",
    "        \"mergeTo\":      \"DimCustomer_clean.csv\",\n",
    "        \"dw_new\":       \"DimCustomer_DW.csv\",\n",
    "        \"mergeBy\":      \"GeographyKey\",\n",
    "        \"tableName\":    \"DimCustomer\",\n",
    "        \"column_2\":     \"no\",\n",
    "        \"column_new\":   \"no\"  \n",
    "    },\n",
    "    2: {\n",
    "        \"mergeFrom\":    \"DimProductGroup_clean.csv\",\n",
    "        \"mergeTo\":      \"DimProduct_clean.csv\",\n",
    "        \"dw_new\":       \"DimProduct_DW.csv\",\n",
    "        \"mergeBy\":      \"ProductGroup_Key\",\n",
    "        \"tableName\":    \"DimProduct\",\n",
    "        \"column_2\":     \"Name_2\",   \n",
    "        \"column_new\":   \"ProductGroup\"\n",
    "    },\n",
    "    3: {\n",
    "        \"mergeFrom\":    \"CDR_clean.csv\",\n",
    "        \"mergeTo\":      \"\",\n",
    "        \"dw_new\":       \"FactCDR_DW.csv\",\n",
    "        \"mergeBy\":      \"\",\n",
    "        \"tableName\":    \"FactCDR\",\n",
    "        \"column_2\":     \"\",   \n",
    "        \"column_new\":   \"\"\n",
    "    },\n",
    "    4: {\n",
    "        \"mergeFrom\":    \"DimAgent_clean.csv\",\n",
    "        \"mergeTo\":      \"\",\n",
    "        \"dw_new\":       \"DimAgent_DW.csv\",\n",
    "        \"mergeBy\":      \"\",\n",
    "        \"tableName\":    \"DimAgent\",\n",
    "        \"column_2\":     \"\",   \n",
    "        \"column_new\":   \"\"\n",
    "    },\n",
    "    5: {\n",
    "        \"mergeFrom\":    \"DimHandleType_clean.csv\",\n",
    "        \"mergeTo\":      \"\",\n",
    "        \"dw_new\":       \"DimHandleType_DW.csv\",\n",
    "        \"mergeBy\":      \"\",\n",
    "        \"tableName\":    \"DimHandleType\",\n",
    "        \"column_2\":     \"\",   \n",
    "        \"column_new\":   \"\"\n",
    "    },\n",
    "    6: {\n",
    "        \"mergeFrom\":    \"DimServiceType_clean.csv\",\n",
    "        \"mergeTo\":      \"\",\n",
    "        \"dw_new\":       \"DimServiceType_DW.csv\",\n",
    "        \"mergeBy\":      \"\",\n",
    "        \"tableName\":    \"DimServiceType\",\n",
    "        \"column_2\":     \"\",   \n",
    "        \"column_new\":   \"\"\n",
    "    },\n",
    "    7: {\n",
    "        \"mergeFrom\":    \"DimSeverifyType_clean.csv\",\n",
    "        \"mergeTo\":      \"\",\n",
    "        \"dw_new\":       \"DimSeverifyType_DW.csv\",\n",
    "        \"mergeBy\":      \"\",\n",
    "        \"tableName\":    \"DimSeverifyType\",\n",
    "        \"column_2\":     \"\",   \n",
    "        \"column_new\":   \"\"\n",
    "    }\n",
    "}\n",
    "transTables = {\n",
    "    \"CDR_clean.csv\":                \"FactCDR\",\n",
    "    \"DimAgent_clean.csv\":           \"DimAgent\",\n",
    "    \"DimHandleType_clean.csv\":      \"DimHandleType\",\n",
    "    \"DimServiceType_clean.csv\":     \"DimServiceType\",\n",
    "    \"DimSeverifyType_clean.csv\":    \"DimSeverifyType\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==== Transform: Merge tables ====\n",
      "\n",
      "From: DimGeography_clean.csv(655, 10)\n",
      "Index(['GeographyKey', 'City', 'StateProvinceCode', 'StateProvinceName',\n",
      "       'CountryRegionCode', 'EnglishCountryRegionName',\n",
      "       'SpanishCountryRegionName', 'FrenchCountryRegionName', 'PostalCode',\n",
      "       'SalesTerritoryKey'],\n",
      "      dtype='object')\n",
      "To: DimCustomer_clean.csv(18484, 34)\n",
      "Index(['CustomerKey', 'GeographyKey', 'CustomerAlternateKey', 'Title',\n",
      "       'FirstName', 'MiddleName', 'LastName', 'NameStyle', 'BirthDate',\n",
      "       'MaritalStatus', 'Suffix', 'Gender', 'EmailAddress', 'YearlyIncome',\n",
      "       'TotalChildren', 'NumberChildrenAtHome', 'EnglishEducation',\n",
      "       'SpanishEducation', 'FrenchEducation', 'EnglishOccupation',\n",
      "       'SpanishOccupation', 'FrenchOccupation', 'HouseOwnerFlag',\n",
      "       'NumberCarsOwned', 'AddressLine1', 'AddressLine2', 'Phone',\n",
      "       'DateFirstPurchase', 'CommuteDistance', 'Title_ismissing',\n",
      "       'MiddleName_ismissing', 'LastName_ismissing', 'Suffix_ismissing',\n",
      "       'AddressLine2_ismissing'],\n",
      "      dtype='object')\n",
      "43\n",
      "['CustomerKey', 'GeographyKey', 'CustomerAlternateKey', 'Title', 'FirstName', 'MiddleName', 'LastName', 'NameStyle', 'BirthDate', 'MaritalStatus', 'Suffix', 'Gender', 'EmailAddress', 'YearlyIncome', 'TotalChildren', 'NumberChildrenAtHome', 'EnglishEducation', 'SpanishEducation', 'FrenchEducation', 'EnglishOccupation', 'SpanishOccupation', 'FrenchOccupation', 'HouseOwnerFlag', 'NumberCarsOwned', 'AddressLine1', 'AddressLine2', 'Phone', 'DateFirstPurchase', 'CommuteDistance', 'Title_ismissing', 'MiddleName_ismissing', 'LastName_ismissing', 'Suffix_ismissing', 'AddressLine2_ismissing', 'City', 'StateProvinceCode', 'StateProvinceName', 'CountryRegionCode', 'EnglishCountryRegionName', 'SpanishCountryRegionName', 'FrenchCountryRegionName', 'PostalCode', 'SalesTerritoryKey']\n",
      "37\n",
      "['CustomerKey', 'City', 'StateProvinceCode', 'StateProvinceName', 'CountryRegionCode', 'EnglishCountryRegionName', 'SpanishCountryRegionName', 'FrenchCountryRegionName', 'PostalCode', 'SalesTerritoryKey', 'CustomerAlternateKey', 'Title', 'FirstName', 'MiddleName', 'LastName', 'NameStyle', 'BirthDate', 'MaritalStatus', 'Suffix', 'Gender', 'EmailAddress', 'YearlyIncome', 'TotalChildren', 'NumberChildrenAtHome', 'EnglishEducation', 'SpanishEducation', 'FrenchEducation', 'EnglishOccupation', 'SpanishOccupation', 'FrenchOccupation', 'HouseOwnerFlag', 'NumberCarsOwned', 'AddressLine1', 'AddressLine2', 'Phone', 'DateFirstPurchase', 'CommuteDistance']\n",
      "GeographyKey\n",
      "Title_ismissing\n",
      "MiddleName_ismissing\n",
      "LastName_ismissing\n",
      "Suffix_ismissing\n",
      "AddressLine2_ismissing\n",
      "5\n",
      "   CustomerKey         City StateProvinceCode StateProvinceName  \\\n",
      "0        11000  Rockhampton               QLD        Queensland   \n",
      "1        11001      Seaford               VIC          Victoria   \n",
      "2        11002       Hobart               TAS          Tasmania   \n",
      "3        11003   North Ryde               NSW   New South Wales   \n",
      "4        11004   Wollongong               NSW   New South Wales   \n",
      "\n",
      "  CountryRegionCode EnglishCountryRegionName SpanishCountryRegionName  \\\n",
      "0                AU                Australia                Australia   \n",
      "1                AU                Australia                Australia   \n",
      "2                AU                Australia                Australia   \n",
      "3                AU                Australia                Australia   \n",
      "4                AU                Australia                Australia   \n",
      "\n",
      "  FrenchCountryRegionName PostalCode  SalesTerritoryKey  ...  \\\n",
      "0               Australie       4700                  9  ...   \n",
      "1               Australie       3198                  9  ...   \n",
      "2               Australie       7001                  9  ...   \n",
      "3               Australie       2113                  9  ...   \n",
      "4               Australie       2500                  9  ...   \n",
      "\n",
      "  EnglishOccupation SpanishOccupation FrenchOccupation HouseOwnerFlag  \\\n",
      "0      Professional       Profesional            Cadre              1   \n",
      "1      Professional       Profesional            Cadre              0   \n",
      "2      Professional       Profesional            Cadre              1   \n",
      "3      Professional       Profesional            Cadre              0   \n",
      "4      Professional       Profesional            Cadre              1   \n",
      "\n",
      "  NumberCarsOwned         AddressLine1       AddressLine2  \\\n",
      "0               0      3761 N. 14th St  Verkaufsabteilung   \n",
      "1               1           2243 W St.  Verkaufsabteilung   \n",
      "2               1     5844 Linden Land  Verkaufsabteilung   \n",
      "3               1     1825 Village Pl.  Verkaufsabteilung   \n",
      "4               4  7553 Harness Circle  Verkaufsabteilung   \n",
      "\n",
      "                 Phone DateFirstPurchase CommuteDistance  \n",
      "0  1 (11) 500 555-0162        2001-07-22       1-2 Miles  \n",
      "1  1 (11) 500 555-0110        2001-07-18       0-1 Miles  \n",
      "2  1 (11) 500 555-0184        2001-07-10       2-5 Miles  \n",
      "3  1 (11) 500 555-0162        2001-07-01      5-10 Miles  \n",
      "4  1 (11) 500 555-0131        2001-07-26       1-2 Miles  \n",
      "\n",
      "[5 rows x 37 columns]\n",
      "\n",
      "Create DW file: DimCustomer_DW.csv(18484, 37)\n",
      "\n",
      "From: DimProductGroup_clean.csv(5, 2)\n",
      "Index(['ProductGroup_Key', 'Name'], dtype='object')\n",
      "To: DimProduct_clean.csv(25, 3)\n",
      "Index(['Product_Key', 'Name', 'ProductGroup_Key'], dtype='object')\n",
      "4\n",
      "['Product_Key', 'Name', 'ProductGroup_Key', 'ProductGroup']\n",
      "3\n",
      "['Product_Key', 'Name', 'ProductGroup']\n",
      "ProductGroup_Key\n",
      "5\n",
      "   Product_Key           Name ProductGroup\n",
      "0            1  Bundle Plan A       Bundle\n",
      "1            2  Bundle Plan B       Bundle\n",
      "2            3  Bundle Plan C       Bundle\n",
      "3            4  Bundle Plan D       Bundle\n",
      "4            5  Bundle Plan E       Bundle\n",
      "\n",
      "Create DW file: DimProduct_DW.csv(25, 3)\n",
      "\n",
      "From: CDR_clean.csv(16011, 19)\n",
      "Index(['CDRID', 'CustomerKey', 'AgentKey', 'CallDate', 'Start_TM', 'End_TM',\n",
      "       'Status', 'Satisfaction', 'FirstResolved', 'HandleType_Key',\n",
      "       'ServiceType_Key', 'SeverityType_Key', 'CallReason_Key', 'NPS',\n",
      "       'ProductKey', 'CustomerTier', 'CustomerSegment', 'CloseDate',\n",
      "       'NPS_ismissing'],\n",
      "      dtype='object')\n",
      "19\n",
      "['CDRID', 'CustomerKey', 'AgentKey', 'CallDate', 'Start_TM', 'End_TM', 'Status', 'Satisfaction', 'FirstResolved', 'HandleType_Key', 'ServiceType_Key', 'SeverityType_Key', 'CallReason_Key', 'NPS', 'ProductKey', 'CustomerTier', 'CustomerSegment', 'CloseDate', 'NPS_ismissing']\n",
      "18\n",
      "['CDRID', 'CustomerKey', 'AgentKey', 'CallDate', 'Start_TM', 'End_TM', 'Status', 'Satisfaction', 'FirstResolved', 'HandleType_Key', 'ServiceType_Key', 'SeverityType_Key', 'CallReason_Key', 'NPS', 'ProductKey', 'CustomerTier', 'CustomerSegment', 'CloseDate']\n",
      "NPS_ismissing\n",
      "5\n",
      "   CDRID  CustomerKey  AgentKey    CallDate             Start_TM  \\\n",
      "0      1        11569        69  2019-01-06  2019-01-06 02:29:01   \n",
      "1      2        11847         9  2019-01-02  2019-01-02 23:10:59   \n",
      "2      3        11081        39  2019-01-06  2019-01-06 08:00:33   \n",
      "3      4        11871        46  2019-01-06  2019-01-06 04:16:00   \n",
      "4      5        11192        90  2019-01-03  2019-01-03 17:15:15   \n",
      "\n",
      "                End_TM     Status  Satisfaction  FirstResolved  \\\n",
      "0  2019-01-06 02:34:01  Processed             5              1   \n",
      "1  2019-01-02 23:20:59  Processed             3              1   \n",
      "2  2019-01-06 08:05:33  Processed             7              0   \n",
      "3  2019-01-06 04:26:00  Processed             5              1   \n",
      "4  2019-01-03 17:20:15  Processed             3              0   \n",
      "\n",
      "   HandleType_Key  ServiceType_Key  SeverityType_Key  CallReason_Key   NPS  \\\n",
      "0               2                1                 2              15  12.0   \n",
      "1               3               14                 1               6   8.0   \n",
      "2               2                9                 1              13   0.0   \n",
      "3               3               14                 1               5   7.0   \n",
      "4               3               12                 3               8   6.0   \n",
      "\n",
      "   ProductKey   CustomerTier CustomerSegment   CloseDate  \n",
      "0           5  PlatinumElite       Segment C  2019-01-09  \n",
      "1           6       Platinum       Segment D  2019-01-05  \n",
      "2           9           Gold       Segment B  2019-01-13  \n",
      "3           3       Platinum       Segment E  2019-01-09  \n",
      "4           8           Gold       Segment C  2019-01-08  \n",
      "\n",
      "Create DW file: FactCDR_DW.csv(16011, 18)\n",
      "\n",
      "From: DimAgent_clean.csv(100, 5)\n",
      "Index(['AgentID', 'FirstName', 'LastName', 'Group', 'Location'], dtype='object')\n",
      "5\n",
      "['AgentID', 'FirstName', 'LastName', 'Group', 'Location']\n",
      "5\n",
      "['AgentID', 'FirstName', 'LastName', 'Group', 'Location']\n",
      "5\n",
      "   AgentID   FirstName  LastName    Group Location\n",
      "0        1      Jarrod      Todd  Level 1   London\n",
      "1        2  Chancellor  Mckenzie  Level 1   Berlin\n",
      "2        3       Lamar      Pace  Level 5   London\n",
      "3        4     Brenden    Nguyen  Level 5    Paris\n",
      "4        5       Micah   Gilbert  Level 2    Paris\n",
      "\n",
      "Create DW file: DimAgent_DW.csv(100, 5)\n",
      "\n",
      "From: DimHandleType_clean.csv(3, 2)\n",
      "Index(['HandleType_Key', 'HandleType_Desc'], dtype='object')\n",
      "2\n",
      "['HandleType_Key', 'HandleType_Desc']\n",
      "2\n",
      "['HandleType_Key', 'HandleType_Desc']\n",
      "3\n",
      "   HandleType_Key HandleType_Desc\n",
      "0               1            Call\n",
      "1               2            Chat\n",
      "2               3           Email\n",
      "\n",
      "Create DW file: DimHandleType_DW.csv(3, 2)\n",
      "\n",
      "From: DimServiceType_clean.csv(16, 2)\n",
      "Index(['ServiceType_Key', 'ServiceType_Desc'], dtype='object')\n",
      "2\n",
      "['ServiceType_Key', 'ServiceType_Desc']\n",
      "2\n",
      "['ServiceType_Key', 'ServiceType_Desc']\n",
      "5\n",
      "   ServiceType_Key              ServiceType_Desc\n",
      "0                1                 Billing Issue\n",
      "1                2    Contact Information Change\n",
      "2                3                Delivery Issue\n",
      "3                4  Contact Cancellation Request\n",
      "4                5        Functionality Question\n",
      "\n",
      "Create DW file: DimServiceType_DW.csv(16, 2)\n",
      "\n",
      "From: DimSeverifyType_clean.csv(3, 2)\n",
      "Index(['SeverityType_Key', 'SeverityType_Desc'], dtype='object')\n",
      "2\n",
      "['SeverityType_Key', 'SeverityType_Desc']\n",
      "2\n",
      "['SeverityType_Key', 'SeverityType_Desc']\n",
      "3\n",
      "   SeverityType_Key SeverityType_Desc\n",
      "0                 1              High\n",
      "1                 2               Low\n",
      "2                 3            Medium\n",
      "\n",
      "Create DW file: DimSeverifyType_DW.csv(3, 2)\n"
     ]
    }
   ],
   "source": [
    "#=============================================================================\n",
    "#=== Transform - Merge table\n",
    "#=============================================================================\n",
    "\n",
    "print('==== Transform: Merge tables ====')\n",
    "os.chdir(my_path_cleaned)\n",
    "for i in mergeTables.values():\n",
    "    mergeFrom = i.get(\"mergeFrom\")\n",
    "    mergeTo = i.get(\"mergeTo\")\n",
    "    dw_new = i.get(\"dw_new\")\n",
    "    mergeBy = i.get(\"mergeBy\")\n",
    "    tableName = i.get(\"tableName\")\n",
    "\n",
    "    # Get data\n",
    "    df_from = pandas.read_csv(mergeFrom)\n",
    "    size_org = df_from.shape[0]\n",
    "    print('\\nFrom: ' + mergeFrom + str(df_from.shape))\n",
    "    print(df_from.columns)\n",
    "    if mergeTo ==\"\":\n",
    "        df_new = df_from\n",
    "    else:\n",
    "        df_to = pandas.read_csv(mergeTo)\n",
    "        size_org = df_to.shape[0]\n",
    "        print('To: ' + mergeTo + str(df_to.shape))\n",
    "        print(df_to.columns)\n",
    "\n",
    "        # Merge two tables\n",
    "        df_new = pandas.merge(df_to, df_from, how = 'left', on = mergeBy, suffixes=('', '_2'))\n",
    "    \n",
    "        #df_new.head()\n",
    "\n",
    "        # Deal with duplicated column names\n",
    "    \n",
    "        if mergeFrom == 'DimProductGroup_clean.csv':\n",
    "            df_new = rename(df_new, ['Name_2'], ['ProductGroup'])\n",
    "        #    df_new = rename(df_new, column_2, column_new)\n",
    "    toNew_column_name = list(df_new.columns)\n",
    "    #for column in toNew_column_name:\n",
    "    #    if column in column_2:\n",
    "    \n",
    "    print(len(toNew_column_name))    \n",
    "    print(toNew_column_name)\n",
    " \n",
    "    # Check destination DW columns\n",
    "    query = \"SELECT * FROM [dbo].[\" + tableName + \"]\"\n",
    "    #print(query)\n",
    "    df_dw = pandas.read_sql(query, sql_dw_conn)\n",
    "    dw_column_name = list(df_dw.columns)\n",
    "    print(len(dw_column_name))    \n",
    "    print(dw_column_name)\n",
    "\n",
    "    for column in toNew_column_name:\n",
    "        if column not in dw_column_name:\n",
    "            print(column)\n",
    "            df_new.drop(column, axis = 1, inplace = True)\n",
    "    #print(df_new.head())\n",
    "\n",
    "    # Rearragnge Columns\n",
    "    df_new = df_new[dw_column_name]\n",
    "    print(len(df_new.head()))\n",
    "    print(df_new.head())\n",
    "\n",
    "    # Export to DW .csv\n",
    "    os.chdir(my_path_CCBISDW)\n",
    "    df_new.to_csv(dw_new, index = False)\n",
    "    df_new = pandas.read_csv(dw_new)\n",
    "    size_org = df_new.shape[0]\n",
    "    print('\\nCreate DW file: ' + dw_new + str(df_new.shape))\n",
    "    os.chdir(my_path_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==== Validation Tables ====\n",
      "\n",
      "From: DimCustomer_DW.csv(18484, 37)\n",
      "\n",
      "From: DimProduct_DW.csv(25, 3)\n"
     ]
    }
   ],
   "source": [
    "#=============================================================================\n",
    "#=== Validation\n",
    "#=============================================================================\n",
    "\n",
    "os.chdir(my_path_CCBISDW)\n",
    "print(\"==== Validation Tables ====\")\n",
    "\n",
    "for file in glob.glob(\"*.csv\"):\n",
    "    # Get table info\n",
    "    tableName = str(file)[:-4]\n",
    "    pkNameQuery = \"SELECT Col.Column_Name as PkName from INFORMATION_SCHEMA.TABLE_CONSTRAINTS Tab, INFORMATION_SCHEMA.CONSTRAINT_COLUMN_USAGE Col WHERE Col.Constraint_Name = Tab.Constraint_Name AND Col.Table_Name = Tab.Table_Name AND Constraint_Type = 'PRIMARY KEY' AND Col.Table_Name = '\" + tableName +\"'\"\n",
    "    pkList = list(pandas.read_sql(pkNameQuery, sql_conn)[\"PkName\"])\n",
    "\n",
    "    # Get data\n",
    "    df = pandas.read_csv(file, index_col = pkList)\n",
    "    size_org = df.shape[0]\n",
    "    print('\\nFrom: ' + file + str(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=============================================================================\n",
    "#=== SQL Bulk Insert Procedue\n",
    "#=============================================================================\n",
    "class c_bulk_insert:\n",
    "    def __init__(self, csv_file_nm, db_nm, db_table_nm):\n",
    "        # Connect to the database, perform the insert, and update the log table.\n",
    "        \n",
    "        conn = self.connect_db()\n",
    "        self.insert_data(conn, csv_file_nm, db_table_nm)\n",
    "        conn.close\n",
    "    def connect_db(self):\n",
    "        # Connect to the server and database with Windows authentication.\n",
    "        # conn_string = 'DRIVER={SQL Server}; SERVER = localhost; DATABASE=' + db_nm + '; UID=sa; PWD=SQLServer2019; Trusted_Connection=yes'\n",
    "        conn = pyodbc.connect('DRIVER={SQL Server}; SERVER=localhost; DATABASE=CCBISDW; UID=sa; PWD=SQLServer2019') \n",
    "        # conn = pyodbc.connect(conn_string)\n",
    "        return conn\n",
    "    def insert_data(self, conn, csv_file_nm, db_table_nm):\n",
    "        # Insert the data from the CSV file into the database table.\n",
    "        # Assemble the BULK INSERT query. Be sure to skip the header row by specifying FIRSTROW = 2.\n",
    "        qry = \"BULK INSERT \" + db_table_nm + \" FROM '\" + csv_file_nm + \"' WITH (FORMAT = 'CSV', FIRSTROW = 2)\"\n",
    "        # Execute the query\n",
    "        cursor = conn.cursor()\n",
    "        success = cursor.execute(qry)\n",
    "        conn.commit()\n",
    "        cursor.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "b'hello world\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "import docker\n",
    "client = docker.from_env()\n",
    "client.containers.run(\"alpine\", \"echo hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=============================================================================\n",
    "#=== Copy .csv to Docker Container Procedue\n",
    "#=============================================================================\n",
    "import docker\n",
    "client = docker.from_env()\n",
    "# src - from file name (in local), shall be an absolute path of fromFile\n",
    "# dst - to dir (in docker container)\n",
    "def copy_to_container(src, dst):\n",
    "    name, dst = dst.split(':')\n",
    "    container = client.containers.get(name)\n",
    "\n",
    "    os.chdir(os.path.dirname(src))\n",
    "    srcname = os.path.basename(src)\n",
    "    tar = tarfile.open(src + '.tar', mode='w')\n",
    "    try:\n",
    "        tar.add(srcname)\n",
    "    finally:\n",
    "        tar.close()\n",
    "\n",
    "    data = open(src + '.tar', 'rb').read()\n",
    "    container.put_archive(os.path.dirname(dst), data)\n",
    "# To use\n",
    "# copy_to_container(\"C:\\MyDataFiles\\Data_CCBIS_202107\\CCBISDW\\DimCustomer_DW.csv\", 'SQL_Server_2019:/var/tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DimAgent\n",
      "C:\\MyDataFiles\\Data_CCBIS_202107\\CCBISDW\\DimAgent_DW.csv\n",
      "SQL_Server_2019:/var/tmp\n",
      "DimCustomer\n",
      "C:\\MyDataFiles\\Data_CCBIS_202107\\CCBISDW\\DimCustomer_DW.csv\n",
      "SQL_Server_2019:/var/tmp\n",
      "DimHandleType\n",
      "C:\\MyDataFiles\\Data_CCBIS_202107\\CCBISDW\\DimHandleType_DW.csv\n",
      "SQL_Server_2019:/var/tmp\n",
      "DimProduct\n",
      "C:\\MyDataFiles\\Data_CCBIS_202107\\CCBISDW\\DimProduct_DW.csv\n",
      "SQL_Server_2019:/var/tmp\n",
      "DimServiceType\n",
      "C:\\MyDataFiles\\Data_CCBIS_202107\\CCBISDW\\DimServiceType_DW.csv\n",
      "SQL_Server_2019:/var/tmp\n",
      "DimSeverifyType\n",
      "C:\\MyDataFiles\\Data_CCBIS_202107\\CCBISDW\\DimSeverifyType_DW.csv\n",
      "SQL_Server_2019:/var/tmp\n",
      "FactCDR\n",
      "C:\\MyDataFiles\\Data_CCBIS_202107\\CCBISDW\\FactCDR_DW.csv\n",
      "SQL_Server_2019:/var/tmp\n"
     ]
    }
   ],
   "source": [
    "# Copy .csv to Docker Container\n",
    "for file in glob.glob(\"*.csv\"):\n",
    "    os.chdir(my_path_CCBISDW)\n",
    "    fileName = os.path.join(my_path_CCBISDW, file)\n",
    "    tableName = str(file)[:-7]\n",
    "    toContainerDir = 'SQL_Server_2019:/var/tmp'\n",
    "    print(tableName)\n",
    "    print(fileName)\n",
    "    print(toContainerDir)\n",
    "    copy_to_container(fileName, toContainerDir)\n",
    "    #bulk_insert = c_bulk_insert(fileName, 'CCBISDW', tableName) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==== Load to WD ====\nDimAgent\nSQL_Server_2019:/var/tmp/DimAgent_DW.csv\nuse CCBISDW BULK INSERT DimAgent FROM 'SQL_Server_2019:/var/tmp/DimAgent_DW.csv' \nselect top (10) * from DimAgent\nDimCustomer\nSQL_Server_2019:/var/tmp/DimCustomer_DW.csv\nuse CCBISDW BULK INSERT DimAgent FROM 'SQL_Server_2019:/var/tmp/DimAgent_DW.csv' \nselect top (10) * from DimCustomer\nDimHandleType\nSQL_Server_2019:/var/tmp/DimHandleType_DW.csv\nuse CCBISDW BULK INSERT DimAgent FROM 'SQL_Server_2019:/var/tmp/DimAgent_DW.csv' \nselect top (10) * from DimHandleType\nDimProduct\nSQL_Server_2019:/var/tmp/DimProduct_DW.csv\nuse CCBISDW BULK INSERT DimAgent FROM 'SQL_Server_2019:/var/tmp/DimAgent_DW.csv' \nselect top (10) * from DimProduct\nDimServiceType\nSQL_Server_2019:/var/tmp/DimServiceType_DW.csv\nuse CCBISDW BULK INSERT DimAgent FROM 'SQL_Server_2019:/var/tmp/DimAgent_DW.csv' \nselect top (10) * from DimServiceType\nDimSeverifyType\nSQL_Server_2019:/var/tmp/DimSeverifyType_DW.csv\nuse CCBISDW BULK INSERT DimAgent FROM 'SQL_Server_2019:/var/tmp/DimAgent_DW.csv' \nselect top (10) * from DimSeverifyType\nFactCDR\nSQL_Server_2019:/var/tmp/FactCDR_DW.csv\nuse CCBISDW BULK INSERT DimAgent FROM 'SQL_Server_2019:/var/tmp/DimAgent_DW.csv' \nselect top (10) * from FactCDR\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<function Cursor.close>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "#=============================================================================\n",
    "#=== Load CSV to DW\n",
    "#=============================================================================\n",
    "os.chdir(my_path_CCBISDW)\n",
    "print(\"==== Load to WD ====\")\n",
    "# Set up SQL Server connector\n",
    "#sql_dw_conn = pyodbc.connect('DRIVER={SQL Server}; SERVER=localhost; DATABASE=CCBISDW; UID=sa; PWD=SQLServer2019')  \n",
    "\n",
    "cursor = sql_dw_conn.cursor()\n",
    "for file in glob.glob(\"*.csv\"):\n",
    "    # Get table info\n",
    "    tableName = str(file)[:-7]\n",
    "    #fileName = str(os.path.join(my_path_CCBISDW, file))\n",
    "    #fileName = os.path.join(toContainerDir,file)\n",
    "    #toName = 'my-container:/tmp/CCBISDW/DimCustomer_DW.csv'\n",
    "    #copy_to(fileName, toName)\n",
    "    toContainerDir = 'SQL_Server_2019:/var/tmp'\n",
    "    fileName = str(toContainerDir + \"/\" + tableName + '_DW.csv')\n",
    "    fileName = str(toContainerDir + \"/\" + tableName + '_DW.csv')\n",
    "    #pkNameQuery = \"SELECT Col.Column_Name as PkName from INFORMATION_SCHEMA.TABLE_CONSTRAINTS Tab, INFORMATION_SCHEMA.CONSTRAINT_COLUMN_USAGE Col WHERE Col.Constraint_Name = Tab.Constraint_Name AND Col.Table_Name = Tab.Table_Name AND Constraint_Type = 'PRIMARY KEY' AND Col.Table_Name = '\" + tableName +\"'\"\n",
    "    #pkList = list(pandas.read_sql(pkNameQuery, sql_dw_conn)[\"PkName\"])\n",
    "    print(tableName)\n",
    "    print(fileName)\n",
    "    #from c_bulk_insert import c_bulk_insert\n",
    "    ########bulk_insert = c_bulk_insert(fileName, 'CCBISDW', tableName) \n",
    "    # Get data\n",
    "    #qry = \"SELECT @@SERVERNAME\"\n",
    "    #qry = \"use CCBISDW BULK INSERT dbo.\" + tableName + \" FROM '\" + toContainerDir + \"' WITH (datafiletype = 'char', FIRSTROW = 2, FIELDTERMINATOR ='\\t', ROWTERMINATOR ='\\n')\"\n",
    "    qry = \"use CCBISDW BULK INSERT DimAgent FROM 'SQL_Server_2019:/var/tmp/DimAgent_DW.csv' \"\n",
    "    print(qry)\n",
    "    cursor.execute(qry)\n",
    "    qry = \"select top (10) * from \" + tableName\n",
    "    print(qry)\n",
    "    cursor.execute(qry)\n",
    "    #success = cursor.execute(qry)\n",
    "    #sql_dw_conn.commit()\n",
    "cursor.close\n",
    "    #df = pandas.read_csv(file, index_col = pkList)\n",
    "    #with open (file, 'r') as f:\n",
    "    #    reader = csv.reader(f)\n",
    "    #    columns = next(reader) \n",
    "\n",
    "    # Insert DataFrame to Table\n",
    "    #insert_data(file, sql_dw_conn, fileName, tableName)\n",
    "        #cursor = sql_dw_conn.cursor()\n",
    "        #query = \"INSERT INTO \" + tableName  + 'values ({1})'\n",
    "        #query = query.format(','.join(columns), ','.join('?' * len(columns)))\n",
    "        #query = \"Use CCBISDW bulk insert dbo.\" + tableName + \"From '\" + my_path_CCBISDW + \"\\\" + file + \"' With(Datafile = \"char\", FIRSTROW = 2, FIELDTERMINATOR = \",\", ROWTERMINATOR = \"0x0a\")\" \n",
    "        #for data in reader:\n",
    "        #    cursor.execute(query, data)\n",
    "        #sql_dw_conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}